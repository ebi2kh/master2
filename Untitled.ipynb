{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1ced16-b326-4b3c-a264-a9a2fd73024b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 128\n",
      "128 128\n",
      "PPO running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eb_khosravi/.conda/envs/eb_khosravi/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epi:00100 || disc_a_r:-131.218 disc_q_r:-134.785\n",
      "Epi:00200 || disc_a_r:-130.938 disc_q_r:-134.567\n",
      "Epi:00222 || model Updated with lr:9.80e-04\n",
      "Epi:00300 || disc_a_r:-129.851 disc_q_r:-133.127\n",
      "Epi:00400 || disc_a_r:-129.577 disc_q_r:-132.749\n",
      "Epi:00445 || model Updated with lr:9.62e-04\n",
      "Epi:00500 || disc_a_r:-127.089 disc_q_r:-131.093\n",
      "Epi:00600 || disc_a_r:-122.435 disc_q_r:-130.953\n",
      "Epi:00668 || model Updated with lr:9.43e-04\n",
      "Epi:00700 || disc_a_r:-117.105 disc_q_r:-125.351\n",
      "Epi:00800 || disc_a_r:-111.414 disc_q_r:-122.473\n",
      "Epi:00891 || model Updated with lr:9.26e-04\n",
      "Epi:00900 || disc_a_r:-114.274 disc_q_r:-123.462\n",
      "Epi:01000 || disc_a_r:-144.725 disc_q_r:-160.953\n",
      "Epi:01100 || disc_a_r:-144.417 disc_q_r:-154.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 147\u001b[0m\n\u001b[1;32m    145\u001b[0m zipped_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(algos, seeds, devices))\n\u001b[1;32m    146\u001b[0m pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mn)\n\u001b[0;32m--> 147\u001b[0m pool\u001b[38;5;241m.\u001b[39mstarmap(run, zipped_list)\n\u001b[1;32m    148\u001b[0m pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    149\u001b[0m pool\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/.conda/envs/eb_khosravi/lib/python3.12/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_async(func, iterable, starmapstar, chunksize)\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m~/.conda/envs/eb_khosravi/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/eb_khosravi/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m~/.conda/envs/eb_khosravi/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.conda/envs/eb_khosravi/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/eb_khosravi/.conda/envs/eb_khosravi/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/eb_khosravi/.conda/envs/eb_khosravi/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/eb_khosravi/.conda/envs/eb_khosravi/lib/python3.12/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/eb_khosravi/.conda/envs/eb_khosravi/lib/python3.12/multiprocessing/pool.py\", line 51, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2276862/3615699706.py\", line 135, in run\n",
      "    agent.train()\n",
      "  File \"/home/eb_khosravi/agents/ppo.py\", line 101, in train\n",
      "    self.update()\n",
      "  File \"/home/eb_khosravi/agents/ppo.py\", line 179, in update\n",
      "    logprobs, state_values, dist_entropy = self.evaluate(old_states[idx], old_actions[idx])\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/eb_khosravi/agents/ppo.py\", line 124, in evaluate\n",
      "    def evaluate(self, state, action):\n",
      "    \n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "import argparse\n",
    "import torch\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "import multiprocessing\n",
    "\n",
    "from agents import PPO, PG, QPO, QPPO, SPSA\n",
    "from envs import ToyEnv, RSMA,RSMA_NO_RIS,NOMA,TDMA\n",
    "\n",
    "\n",
    "class Options(object):\n",
    "    def __init__(self, algo_name):\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--env_name', type=str, default='ToyEnv')\n",
    "        parser.add_argument('--algo_name', type=str, default=algo_name)\n",
    "        parser.add_argument('--q_alpha', type=float, default=0.25)\n",
    "        # parser.add_argument('--q_alpha', type=float, default=0.1)\n",
    "        parser.add_argument('--est_interval', type=int, default=100)\n",
    "        parser.add_argument('--log_interval', type=int, default=100)\n",
    "        # parser.add_argument('--max_episode', type=int, default=200000)\n",
    "        parser.add_argument('--max_episode', type=int, default=150000)\n",
    "        # parser.add_argument('--emb_dim', type=list, default=[8,8])\n",
    "        # ****** My Code ****** #\n",
    "\n",
    "\n",
    "        parser.add_argument('--emb_dim', type=list, default=[128,128])\n",
    "        # parser.add_argument('--emb_dim', type=list, default=[256,256])\n",
    "        # ****** My Code ****** #\n",
    "\n",
    "        parser.add_argument('--init_std', type=float, default=np.sqrt(1e-1))\n",
    "        parser.add_argument('--gamma', type=float, default=0.99)\n",
    "        # parser.add_argument('--gamma', type=float, default=0.95)\n",
    "\n",
    "        # lr = a / (b + episode) ** c\n",
    "        parser.add_argument('--theta_a', type=float, default=(10000**0.9)*1e-3)\n",
    "        parser.add_argument('--theta_b', type=float, default=10000)\n",
    "        parser.add_argument('--theta_c', type=float, default=0.9)\n",
    "        parser.add_argument('--q_a', type=float, default=(10000**0.6)*1e-2)\n",
    "        parser.add_argument('--q_b', type=float, default=10000)\n",
    "        parser.add_argument('--q_c', type=float, default=0.6)\n",
    "\n",
    "        args = parser.parse_args(args=[])\n",
    "        if args.algo_name == 'QPPO':\n",
    "            parser.add_argument('--lambda_gae_adv', type=float, default=0.95)\n",
    "            parser.add_argument('--clip_eps', type=float, default=0.2)\n",
    "            parser.add_argument('--vf_coef', type=float, default=0.5)\n",
    "            parser.add_argument('--ent_coef', type=float, default=0.00)\n",
    "            parser.add_argument('--upd_interval', type=int, default=2000)\n",
    "            parser.add_argument('--upd_step', type=int, default=5)\n",
    "            parser.add_argument('--mini_batch', type=int, default=100)\n",
    "            parser.add_argument('--T', type=int, default=10)\n",
    "            parser.add_argument('--T0', type=int, default=5)\n",
    "        if args.algo_name == 'SPSA':\n",
    "            parser.add_argument('--spsa_batch', type=int, default=5)\n",
    "            parser.add_argument('--perturb_c', type=float, default=1.9)\n",
    "            parser.add_argument('--perturb_gamma', type=float, default=1/6)\n",
    "        if args.algo_name == 'PPO':\n",
    "            parser.add_argument('--lambda_gae_adv', type=float, default=0.95)\n",
    "            parser.add_argument('--clip_eps', type=float, default=0.2)\n",
    "            parser.add_argument('--vf_coef', type=float, default=0.5)\n",
    "            parser.add_argument('--ent_coef', type=float, default=0.00)\n",
    "            parser.add_argument('--upd_interval', type=int, default=2000)\n",
    "            parser.add_argument('--upd_step', type=int, default=10)\n",
    "            parser.add_argument('--mini_batch', type=int, default=100)\n",
    "        self.parser = parser\n",
    "\n",
    "    def parse(self, seed=0, device='0'):\n",
    "        args = self.parser.parse_args(args=[])\n",
    "        args.seed = seed\n",
    "        args.device = torch.device(\"cuda:\" + device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        current_time = re.sub(r'\\D', '', str(datetime.datetime.now())[4:-7])\n",
    "        args.path = './logs/' + args.env_name + '/' + args.algo_name + '_' + current_time + '_' + str(args.seed)\n",
    "        os.makedirs(args.path)\n",
    "        return args\n",
    "\n",
    "\n",
    "def run(algo_name, seed, device):\n",
    "    args = Options(algo_name).parse(seed, str(device))\n",
    "\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    # env = ToyEnv(n=10)\n",
    "\n",
    "    # ***** My Code ***** #\n",
    "    # env = RSMA(n_users=20) # set the number of users\n",
    "    # env = RSMA(n_users=16) # set the number of users\n",
    "    # env = RSMA(n_users=15) # set the number of users\n",
    "    # env = RSMA(n_users=12) # set the number of users\n",
    "    # env = RSMA(n_users=10) # set the number of users\n",
    "    # env = RSMA(n_users=8) # set the number of users\n",
    "    # env = RSMA(n_users=6) # set the number of users\n",
    "\n",
    "    # env = RSMA(n_users=8) # set the number of users\n",
    "    env = RSMA(4,2) # set the number of users\n",
    "    # env = RSMA(n_users=2) # set the number of users\n",
    "\n",
    "    # env = NOMA(n_users=20) # set the number of users\n",
    "    # env = NOMA(n_users=16) # set the number of users\n",
    "    # env = NOMA(n_users=12) # set the number of users\n",
    "    # env = NOMA(n_users=8) # set the number of users\n",
    "    # env = NOMA(n_users=6) # set the number of users\n",
    "    # env = NOMA(n_users=4) # set the number of users\n",
    "\n",
    "\n",
    "\n",
    "    # env = TDMA(n_users=20) # set the number of users\n",
    "    # env = TDMA(n_users=16) # set the number of users\n",
    "    # env = TDMA(n_users=12) # set the number of users\n",
    "    # env = TDMA(n_users=8) # set the number of users\n",
    "    # env = TDMA(n_users=4) # set the number of users\n",
    "\n",
    "\n",
    "    # env = RSMA_NO_RIS(n_users=4) # set the number of users\n",
    "    # env = NOMA(n_users=20) # set the number of users\n",
    "    # env = TDMA(n_users=20) # set the number of users\n",
    "    # ***** My Code ***** #\n",
    "\n",
    "    if args.algo_name == 'PPO':\n",
    "        agent = PPO(args, env)\n",
    "    elif args.algo_name == 'QPPO':\n",
    "        agent = QPPO(args, env)\n",
    "    elif args.algo_name == 'PG':\n",
    "        agent = PG(args, env)\n",
    "    elif args.algo_name == 'QPO':\n",
    "        agent = QPO(args, env)\n",
    "    else:\n",
    "        agent = SPSA(args, env)\n",
    "    print(args.algo_name + ' running')\n",
    "    agent.train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n = 1\n",
    "    # algos = ['SPSA']*n\n",
    "    algos = ['PPO']*n\n",
    "    # algos = ['QPPO']*n\n",
    "    seeds = [i for i in range(n)]\n",
    "    devices = [0 for i in range(n)]\n",
    "    zipped_list = list(zip(algos, seeds, devices))\n",
    "    pool = multiprocessing.Pool(processes=n)\n",
    "    pool.starmap(run, zipped_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206077e-13b1-4f9a-bb2f-d264e482f186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3b26e-59ae-4440-9abd-4f9e1370879e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eb_khosravi)",
   "language": "python",
   "name": "eb_khosravi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
